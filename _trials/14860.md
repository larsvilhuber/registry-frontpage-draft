---
title: "Effect of A.I. Evaluators on Creative Output"
rct_id: "AEARCTR-0014860"
rct_id_num: "14860"
doi: "10.1257/rct.14860-1.0"
date: "2024-11-18"
status: "in_development"
jel: ""
start_year: "2024-11-18"
end_year: "2024-12-02"
pi: "Jason Sandvik"
pi_other:
abstract: "Previous research suggests that quantity-based incentives can be just as effective as quality-based incentives in driving creative outcomes. A potentially non-trivial cost to quantity-based incentives, though, is that it increases the number of items that managers need to evaluate. Artificial intelligence (A.I.) programs provide a way for managers to evaluate creative content quickly, allowing them to assess the quality of a large amount of content in a relatively short amount of time. However, the use of A.I. to evaluate the quality of creative content could discourage workers from developing and sharing their innovative ideas if they are uncertain as to how A.I. will evaluate their content, or if they are meaningfully averse towards algorithmic evaluations of their creative content. We conduct an experiment to see how participation in a creative idea-sharing contest is impacted based on the types of evaluators that are used to evaluate the submissions—A.I. evaluators versus human evaluators—and based on whether quantity-based incentives or quality-based incentives are used. "
layout: registration
---

