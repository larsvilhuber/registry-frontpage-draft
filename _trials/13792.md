---
title: "Do people trust generative AI, and is it trustworthy? An experiment with ChatGPT"
rct_id: "AEARCTR-0013792"
rct_id_num: "13792"
doi: "10.1257/rct.13792-1.0"
date: "2024-07-11"
status: "in_development"
jel: "C91, C93, D90, D91"
start_year: "2024-07-15"
end_year: "2024-08-30"
pi: "Jeffrey Livingston"
pi_other:
  1:
    name: Samson Shen
    email: 
    affiliation: University of Minnesota
  2:
    name: Kobe Rankich
    email: 
    affiliation: University of Washington
abstract: "We measure whether and how much people trust generative AI by having them play Trust Games (Berg et al. 1995) with ChatGPT. Subjects are given $10 and are can send any portion of this to ChatGPT, which is tripled. ChatGPT then decides how much of what it receives to the subject. There are three treatments: Treatment Self-Interest, Treatment Fairness, and Treatment No Prompt. 

In each treatment, we vary the prompt that instructs ChatGPT how to play the game. In Treatment Self-Interest, ChatGPT is told to determine how much to return to the subject "as a rational person would." In Treatment Fairness, ChatGPT is told to determine how much to return to the subject "as a person who believes in fairness and reciprocity" would. In Treatment No Prompt, ChatGPT is given no instructions on how it should decide how much to return to the subject.

The experiment is within-subject; each person plays the game three times (once for each treatment). We randomize the order of the treatments. One game is randomly chosen to determine payments to the subject. "
layout: registration
---

