---
title: "Data-Driven Instruction in Honduras: An Impact Evaluation of the EducAcción Promising Reading Intervention"
rct_id: "AEARCTR-0000780"
rct_id_num: "780"
doi: "10.1257/rct.780-5.0"
date: "2015-10-05"
status: "on_going"
jel: "I20"
start_year: "2014-10-01"
end_year: "2018-09-30"
pi: "Sarah Liuzzi"
pi_other:
  1:
    - name: Chantal Toledo
    - email: ctoledo@mathematica-mpr.com
    - affiliation: Mathematica Policy Research
  2:
    - name: Steven Glazerman
    - email: SGlazerman@Mathematica-Mpr.com
    - affiliation: Mathematica Policy Research
  3:
    - name: Nancy Murray
    - email: NMurray@Mathematica-Mpr.com
    - affiliation: Mathematica Policy Research
  4:
    - name: Sarah Humpage-Liuzzi
    - email: SLiuzzi@mathematica-mpr.com
    - affiliation: Mathematica Policy Research
abstract: "As policymakers’ focus in developing countries shifts from school access to school quality, student assessment has come to the fore. Governments use assessment data not only to monitor educational progress, but to provide feedback aimed at improving teaching and learning. In this evaluation, we focus on the potential effects of formative assessment (FA), in which teachers use frequent assessments of their students to improve their teaching, and end-of-grade (EOG) summative assessments, which, like FAs, can be the basis for teachers and principals to adapt their teaching practices and curricula to better meet the needs of their students. 

We undertake a randomized controlled trial (RCT) in 180 schools in Honduras, complemented by qualitative analysis, to estimate the impacts of providing print materials and pedagogical support to maximize teachers’ ability to take advantage of these assessments. To do this, we randomize schools into 3 experimental groups: EOG wrap-around support and FA with support (Group A), EOG wrap-around support only (Group B), and ongoing programming by Honduras’ Ministry of Education (MOE) (Group C, the control group). Group C has limited access to printed FA materials from the Ministry’s previous efforts to distribute them. All schools administer an EOG test, but only schools in Groups A and B receive the intervention’s training and wrap-around support. We collected baseline data in October and November 2014 at the end of the school year. We conducted random assignment in January 2015. The intervention began in June 2015 and we began baseline analysis in June 2015. We will collect follow-up data at the end of 2015 and 2016. 

This design allows us to answer three main sets of research questions. First, we will compare the outcomes of teachers and students in schools assigned to group A to those in schools assigned to group B. This first comparison allows us to provide unbiased estimates of the impact of the FA intervention, holding constant the EOG wrap-around support intervention. Second, we will compare the outcomes of teachers and students in schools assigned to group B to those in schools assigned to group C. This comparison allows us to provide unbiased estimates of the impact of the EOG wrap-around support intervention compared to the ongoing programming provided by MOE and other organizations. Third, we will also be able to compare the outcomes of teachers and students in schools assigned to group A to those in schools assigned to group C. This comparison allows us to provide unbiased estimates of the impact of the combined use of EOG wrap-around support and FA with support, compared to the ongoing programming provided by MOE and other organizations. We will estimate each intervention’s impact on process outcomes (teachers’ access to assessment materials and results), intermediate outcomes (teachers’ use of assessment results to modify instruction), and final outcomes (learning, as measured by EOG tests and an independent assessment). We will estimate impacts at the end of the first and second years of the interventions (the 2015 and 2016 academic years). We will evaluate impacts on teaching methods at the end of both years, and will evaluate impacts on reading and math test scores at the end of the second year of the intervention. 

This study will also include an implementation study which will help demonstrate how the interventions are implemented in reality, and if the implementation differed from the original plans. The implementation study will consist of gathering and analyzing qualitative and quantitative data on what interventions were implemented, and how. Qualitative data collection will consist of key informant interviews and focus groups. In addition, if we find that the intervention is effective, we will also conduct cost-effectiveness analysis. 

A rigorous evaluation of the impact of these types of assessments in Honduras will contribute to a growing body of evidence on what works to improve early grade reading in primary schools, and more generally will test the effectiveness and costs of promising reading and education-access interventions. This evaluation is part of a five-year project to rigorously evaluate and cost United States Agency for International Development (USAID) investments in early literacy and access to education in conflict settings in Latin America and the Caribbean (LAC). Mathematica is currently leading multi-year studies in four countries: Guatemala, Honduras, Nicaragua and Peru. This intervention and the evaluation of the intervention are funded by USAID.

"
layout: registration
---

